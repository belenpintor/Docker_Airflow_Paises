[2023-07-26 13:47:39,821] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: dag_con_conexion_postgres.crear_tabla_ manual__2023-07-26T13:47:15.717266+00:00 [queued]>
[2023-07-26 13:47:39,946] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: dag_con_conexion_postgres.crear_tabla_ manual__2023-07-26T13:47:15.717266+00:00 [queued]>
[2023-07-26 13:47:39,959] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-07-26 13:47:39,980] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2023-07-26 13:47:39,987] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-07-26 13:47:40,172] {taskinstance.py:1397} INFO - Executing <Task(PostgresOperator): crear_tabla_> on 2023-07-26 13:47:15.717266+00:00
[2023-07-26 13:47:40,247] {standard_task_runner.py:52} INFO - Started process 250 to run task
[2023-07-26 13:47:40,355] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'dag_con_conexion_postgres', 'crear_tabla_', 'manual__2023-07-26T13:47:15.717266+00:00', '--job-id', '82', '--raw', '--subdir', 'DAGS_FOLDER/dag_etl_paises.py', '--cfg-path', '/tmp/tmp6er2wowj', '--error-file', '/tmp/tmp6ei_wchq']
[2023-07-26 13:47:40,387] {standard_task_runner.py:80} INFO - Job 82: Subtask crear_tabla_
[2023-07-26 13:47:42,868] {task_command.py:371} INFO - Running <TaskInstance: dag_con_conexion_postgres.crear_tabla_ manual__2023-07-26T13:47:15.717266+00:00 [running]> on host 484a5a9deba0
[2023-07-26 13:47:45,440] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Belenpintor
AIRFLOW_CTX_DAG_ID=dag_con_conexion_postgres
AIRFLOW_CTX_TASK_ID=crear_tabla_
AIRFLOW_CTX_EXECUTION_DATE=2023-07-26T13:47:15.717266+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-07-26T13:47:15.717266+00:00
[2023-07-26 13:47:45,820] {base.py:68} INFO - Using connection ID 'redshift_belen' for task execution.
[2023-07-26 13:47:47,820] {dbapi.py:231} INFO - Running statement: 
CREATE TABLE IF NOT EXISTS bapintor_coderhouse.ciudades (
    city VARCHAR PRIMARY KEY,
    "Housing" DECIMAL(10, 2),
    "Cost of Living" DECIMAL(10, 2),
    "Startups" DECIMAL(10, 2),
    "Venture Capital" DECIMAL(10, 2),
    "Travel Connectivity" DECIMAL(10, 2),
    "Commute" DECIMAL(10, 2),
    "Business Freedom" DECIMAL(10, 2),
    "Safety" DECIMAL(10, 2),
    "Healthcare" DECIMAL(10, 2),
    "Education" DECIMAL(10, 2),
    "Environmental Quality" DECIMAL(10, 2),
    "Economy" DECIMAL(10, 2),
    "Taxation" DECIMAL(10, 2),
    "Internet Access" DECIMAL(10, 2),
    "Leisure & Culture" DECIMAL(10, 2),
    "Tolerance" DECIMAL(10, 2),
    "Outdoors" DECIMAL(10, 2),
    "process_date" TIMESTAMP DISTKEY
);, parameters: None
[2023-07-26 13:47:47,991] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 211, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 235, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.InsufficientPrivilege: permission denied for schema bapintor_coderhouse

[2023-07-26 13:47:48,644] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=dag_con_conexion_postgres, task_id=crear_tabla_, execution_date=20230726T134715, start_date=20230726T134739, end_date=20230726T134748
[2023-07-26 13:47:49,597] {standard_task_runner.py:97} ERROR - Failed to execute job 82 for task crear_tabla_ (permission denied for schema bapintor_coderhouse
; 250)
[2023-07-26 13:47:50,059] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-07-26 13:47:51,367] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
